# Daily Paper Reading

#### 2022/12/19

- [x] Reproducible scaling laws for contrastive language-image learning: [arXiv](https://arxiv.org/pdf/2212.07143.pdf);

#### 2022/12/25

- [x] Scaling Language-Image Pre-training via Masking: [arXiv](https://arxiv.org/pdf/2212.00794.pdf); [Note]()
- [x] CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet: [arXiv](https://arxiv.org/pdf/2212.06138); [Note]()

#### 2022/12/26

- [x] Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models: [arXiv](https://arxiv.org/pdf/2212.03860); [Note]()
- [x] Multimodal Masked Autoencoders Learn Transferable Representations: [arXiv](https://arxiv.org/abs/2205.14204)

